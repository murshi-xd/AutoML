datasource: 
https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page


reqfile;
'''

click==8.1.3
matplotlib==3.7.5
mlflow==2.19.0
mlflow-skinny==2.19.0
numpy==1.24.4
pandas==2.0.3
scikit_learn==1.3.2
seaborn==0.13.2
statsmodels==0.14.1
zenml
zenml[server]

''''




test:

eda routes:
export PYTHONPATH=$(pwd)/backend
python -m unittest test_eda_routes.py

upload:
python -m unittest tests/test_upload.py




step 1:

create environment:-
conda create -n automl python=3.11

activate env:-
conda activate automl  

step 2 ;

cd backend


Once virtualenv environment is activated, run following command:-
pip install -r requirements.txt

(note:-
        Add additional dependencies: If you add more libraries during your project, you can update the requirements.txt using:-

        pip freeze > requirements.txt

        I have did "pip freeze" to make sure every dependencies are updating to the requirements file.)


step 3:

initialise zenml:-

zenml init 

stop current zenml integrations:-
rm -rf .zen


step 4 :


If you are running the run_deployment.py script, you will also need to install some integrations using ZenML:-

zenml integration install mlflow -y 

The project can only be executed with a ZenML stack that has an MLflow experiment tracker and model deployer as a component. Configuring a new stack with the two components are as follows:-

zenml integration install mlflow -y
zenml experiment-tracker register mlflow_tracker --flavor=mlflow
zenml model-deployer register mlflow --flavor=mlflow
zenml stack register local-mlflow-stack -a default -o default -d mlflow -e mlflow_tracker --set


Set the Environment Variable Temporarily:

You can set the environment variable for the current terminal session. This will only last until you close the terminal or start a new session as :-

step 5: 
export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES

step 6:
run zenml local server by using and just press login :-

zenml up


or 

zenml login --local


# jupyter notebook setup

ipykernel and jupyter is installed from requirements

setup kernal for the environment and use it on vscode kernal for eda.ipynb
run : python -m ipykernel install --user --name=nycenv --display-name "NYCEnv"



if you have issues with the zenml stack active mlflow tracking  ;
üõ†Ô∏è What's the Problem?
You‚Äôve already:

Registered mlflow_tracker

Registered mlflow as a model deployer

But your active stack (default) doesn't use them yet.

So, when you run:

python
Copy
Edit
Client().active_stack.experiment_tracker
‚Ä¶it returns None, because the stack has no experiment tracker set.

‚úÖ Step-by-Step Fix
‚úÖ 1. Check Existing Components
Run:

bash
Copy
Edit
zenml experiment-tracker list
zenml model-deployer list
You should see:

mlflow_tracker (experiment tracker)

mlflow (model deployer)

If not, let me know and we‚Äôll register again.

‚úÖ 2. Register a New Complete Stack (or Overwrite)
Since your default stack doesn't include experiment tracker/model deployer, either:

Option A: Create a new one (recommended)
bash
Copy
Edit
zenml stack register local-mlflow-stack \
  --orchestrator=default \
  --artifact-store=default \
  --experiment-tracker=mlflow_tracker \
  --model-deployer=mlflow
Then activate it:

bash
Copy
Edit
zenml stack set local-mlflow-stack
‚úÖ 3. Confirm Stack Is Correct
Run:

bash
Copy
Edit
zenml stack describe
You should now see:

cpp
Copy
Edit
‚îÉ COMPONENT_TYPE     ‚îÇ COMPONENT_NAME     ‚îÉ
‚îÉ ORCHESTRATOR       ‚îÇ default            ‚îÉ
‚îÉ ARTIFACT_STORE     ‚îÇ default            ‚îÉ
‚îÉ EXPERIMENT_TRACKER ‚îÇ mlflow_tracker     ‚îÉ
‚îÉ MODEL_DEPLOYER     ‚îÇ mlflow             ‚îÉ
‚úÖ 4. Restart Your Backend App
Now that the stack is complete, go back to your Flask app and rerun:

bash
Copy
Edit
python app.py
Now your pipeline should no longer raise this:

pgsql
Copy
Edit
AttributeError: 'NoneType' object has no attribute 'name'


if the port is already in use:

Option 1: Kill the process on port 5004
Run this command to find the PID (process ID):

bash
Copy
Edit
lsof -i :5004
It will show something like:

graphql
Copy
Edit
COMMAND   PID   USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME
python3  12345 murshid   3u  IPv4 0x.....      0t0  TCP localhost:5004 (LISTEN)
Kill that process:

bash
Copy
Edit
kill -9 12345


postman :
http://localhost:5004/run_pipeline
{
  "file_path": "/Users/muhammedmurshid/Documents/Projects/AutoML/AutoML/backend/core/data/archive.zip",
  "feature_strategy": "log",
  "feature_columns": ["Gr Liv Area", "SalePrice"],
  "outlier_column": "SalePrice",
  "target_column": "SalePrice"
}

returns:
{
  "file_path": "/Users/muhammedmurshid/Documents/Projects/AutoML/AutoML/backend/core/data/archive.zip",
  "feature_strategy": "log",
  "feature_columns": ["Gr Liv Area", "SalePrice"],
  "outlier_column": "SalePrice",
  "target_column": "SalePrice"
}